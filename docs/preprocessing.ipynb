{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water dataset:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the water dataset all the attributes' names have changed, there were categories and subcategories, they have been changed to both categories in one name. So from 'National' with subcategory 'Basic', the atributes' name changed to 'NATIONAL-Basic'.\n",
    "\n",
    "A lot of attributes had strings in them indicating a value lower than 1 or higher than 99, these values have been changed to the floats 1.0 and 99.0 respectivly per column like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# originaldf = pd.read_csv('originaldatasets/water_original.csv')\n",
    "# for i in originaldf.columns:\n",
    "#     print(i, originaldf.iloc[1])\n",
    "#  gives \n",
    "# NATIONAL                                             At least basic\n",
    "    # Unnamed: 6                              Limited (more than 30 mins)\n",
    "    # Unnamed: 7                                               Unimproved\n",
    "    # Unnamed: 8                                            Surface water\n",
    "    # Unnamed: 9                           Annual rate of change in basic\n",
    "    # RURAL                                                At least basic\n",
    "    #      Now we can 'manually' change the attribute names like this:\n",
    "    # originaldf = originaldf.rename(columns={'Unnamed: 6': 'NATIONAL-Basic'})\n",
    "    # and so on \n",
    "\n",
    "\n",
    "#df['NATIONAL-Basic'] = df['NATIONAL-Basic'].replace('>99', 99)\n",
    "# the same with <1 to 1.0\n",
    "\n",
    "# Missing data in this dataset has been indicated by '-' in order to make this \n",
    "# NaN we used this line:\n",
    "# df['National-Basic'].replace('-', float('nan'), inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data was not a huge problem since there was not that much, usually skipping a year or a country simply had no data for an attribute, this is why all the attributes have had a 'personal' way of fixing that missing data. Not all attributes were used/ usefull so they have not all been preprocessed on missing data.\n",
    "An example how NATIONAL-Basic was preprocessed can be found here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We made sure the countries were seperated with correcting missing data and repeated the same proces with bfil()\n",
    "# df['NATIONAL-Basic'] = df.groupby('Country')['NATIONAL-Basic'].ffill()\n",
    "\n",
    "# Since there was a trend in this attribute, slow change, \n",
    "# and since this data has been used in bulk so not looking at every little detail \n",
    "# we forward and backward filled it. This led to no weird data and \n",
    "# everything checked out."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this all (preprocessed) rows were checked compared to the original dataset to see if everything went according to plan."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest of the datasets\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other 4 datasets all had nearly the same structure so followed large chucks of the same code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the original file\n",
    "# df = pd.read_csv('originaldatasets/GREEN_GROWTH_13062023131420405.csv')\n",
    "\n",
    "# Pivot the data using groupby and unstack\n",
    "# df_pivoted = df.groupby(['Country', 'Year', 'Variable'])['Value'].first().unstack()\n",
    "\n",
    "# Reset the index\n",
    "# df_pivoted.reset_index(inplace=True)\n",
    "\n",
    "# Save the pivoted data to a new CSV file\n",
    "# df_pivoted.to_csv('pivoted_data_GREEN_GROWTH.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code I took the original GREEN GROWTH dataset where the variables were in a single column and took each unique variable and made it its own column whilst keeping the Country, Year and Value intact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read the CSV file\n",
    "# df = pd.read_csv('originaldatasets/MEI_REAL_13062023132859795.csv')\n",
    "\n",
    "# # Pivot the data using groupby and unstack\n",
    "# df_pivoted = df.groupby(['Country', 'Time', 'Subject'])['Value'].first().unstack()\n",
    "\n",
    "# # Reset the index\n",
    "# df_pivoted.reset_index(inplace=True)\n",
    "\n",
    "# # Save the pivoted data to a new CSV file\n",
    "# df_pivoted.to_csv('pivoted_data_MEI.csv', index=False)\n",
    "# import pandas as pd\n",
    "\n",
    "# # Read the CSV file\n",
    "# df = pd.read_csv('GREEN_GROWTH_13062023131420405.csv')\n",
    "\n",
    "# # Pivot the data using groupby and unstack\n",
    "# df_pivoted = df.groupby(['Country', 'Year', 'Variable'])['Value'].first().unstack()\n",
    "\n",
    "# # Reset the index\n",
    "# df_pivoted.reset_index(inplace=True)\n",
    "\n",
    "# # Save the pivoted data to a new CSV file\n",
    "# df_pivoted.to_csv('pivoted_data_GREEN_GROWTH.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code I took the original MEI dataset where the variables were in a single column and took each unique variable and made it its own column whilst keeping the Country, Time and Value intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read the CSV file\n",
    "# df = pd.read_csv('originaldatasets/REGION_INNOVATION_13062023132043749.csv')\n",
    "\n",
    "# # Pivot the data using groupby and unstack\n",
    "# df_pivoted = df.groupby(['Country', 'Year', 'Indicator'])['Value'].first().unstack()\n",
    "\n",
    "# # Reset the index\n",
    "# df_pivoted.reset_index(inplace=True)\n",
    "\n",
    "# # Save the pivoted data to a new CSV file\n",
    "# df_pivoted.to_csv('pivoted_data_inno.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code I took the original innovation dataset where the variables were in a single column and took each unique variable and made it its own column whilst keeping the Country, Time and Value intact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Read the CSV file\n",
    "# df = pd.read_csv('originaldatasets/ITF_INDICATORS_12062023142856355.csv')\n",
    "\n",
    "# # Pivot the data using groupby and unstack\n",
    "# df_pivoted = df.groupby(['Country', 'Year', 'Indicator'])['Value'].first().unstack()\n",
    "\n",
    "# # Reset the index\n",
    "# df_pivoted.reset_index(inplace=True)\n",
    "\n",
    "# # Save the pivoted data to a new CSV file\n",
    "# df_pivoted.to_csv('pivoted_data_ITF_INFRA.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this code I took the original industry dataset where the variables were in a single column and took each unique variable and made it its own column whilst keeping the Country, Time and Value intact.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
